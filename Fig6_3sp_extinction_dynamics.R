###############################################################################
### Figure 6 - Markov model of time-to-extinction in 3-species community ######
###############################################################################

# Nick Lowery and Tristan Ursell
# 2018
# 
# This script generates Figure 6 from our preprint:
# Structured environments fundamentally alter dynamics and stability of ecological communities
# https://www.biorxiv.org/content/early/2018/07/10/366559
# 
# The script reads in metadata files, as generated by the LV_competition_function.m 
# function.  Code used to generate the cleaned data tables is included below but 
# commented out.  This script calculates the time to extinction in the three species
# simulations, as a function of the environmental structure (i.e., predisposed
# to chaotic, mixed or cyclic dynamics in shorter simulations [see Figure 5], 
# referred to here as initial conditions).  These time-to-extinction distributions
# are then used to fit the shape parameters of the theoretical distribution based
# on the closed-form solution of the corresponding Markov model (see the paper SI).

###############################################################################

# library(R.matlab)
# library(data.table)
library(tidyverse)
library(cowplot)

# # read in raw data files (long)
# trans.metadata.raw <- list.files("3sp_trans_prob", pattern = ".mat", full.names = T) %>%
#   lapply(., readMat)
# 
# # get data organized into tbl
# trans.metadata <- trans.metadata.raw %>% {
#   tibble(
#     L = map_dbl(., "L"),
#     N = map_dbl(., "N"),
#     P = map_dbl(., "P"),
#     pillars = map_dbl(., "pillarq"),
#     R = map_dbl(., "R"), 
#     dx = map_dbl(., "dx"),
#     rep = map_dbl(., "rep"),
#     t.stop = map_dbl(., "t.stop"),
#     data = map(., `[`, c("meanA.out", "meanB.out", "meanC.out")) %>% map(data.frame)
#   )
#   } %>%
#   mutate(t.extinct = t.stop/20) %>%
#   unnest()
#
# fwrite(trans.metadata, file = "3sp_trans_prob_metadata.csv")
# 
# trans.metadata <- fread("3sp_trans_prob_metadata.csv") %>% as.tibble()
# 
# t.extinct <- trans.metadata %>%
#   select(R, rep, t.stop) %>%
#   distinct() %>%
#   mutate(t.extinct = t.stop / 100,
#          ic = fct_recode(factor(R), chaos = "10", mixed = "30", lc = "50")) %>%
#   select(ic, t.extinct) 
#   
# write_csv(t.extinct, "dynamic_transition_extinction_times.csv")
t.extinct <- read_csv("dynamic_transition_extinction_times.csv", col_types = "cd")

# extract extinction times by initial condition 
chaos.extinct <- t.extinct$t.extinct[1:1000]
mix.extinct <- t.extinct$t.extinct[1001:2000]
lc.extinct <- t.extinct$t.extinct[2001:3000]


###############################################################################
### custom fit optimizer - least squares on CDFs ##############################
###############################################################################

# define probability density functions (similar to dnorm, pnorm, etc.)
  # The probability density function is solved for analytically (see SI in paper)
  # An offset term is included to account for the 'grow-in' period 
  #   before the kinetic model effects are expected to operate

# probability density function
  # x is vector of extinction times, off = offset, K and tau are model shape parameters
dext <- function(x, off, K, tau) {
  d = 2*K/sqrt(1-4*K) * exp(-(x-off)/(2*tau)) * sinh((x-off)/(2*tau)*sqrt(1-4*K))
  # ensure no negative probabilities
  d[d < 0] <- 0
  return(d)
}

# vectorized numeric integration function
int_vec <- function(q, off, K, tau) integrate(dext, off = off, K = K, tau = tau, lower = off, upper = q)$value

# cumulative probability function
pext <- function(q, off, K, tau) {
  Z <- integrate(dext, off = off, K = K, tau = tau, lower = off, upper = max(q))$value
  # restrict q < offset to probability of zero
  pad <- rep(0, off)
  res <- sapply(q[q > off], FUN = int_vec, off, K, tau)
  res <- c(pad, res)
  res/Z
}


### mixed initial conditions ###

# calculate empirical cumulative density function
mix.ecdf <- ecdf(mix.extinct)
my.ecdf <- mix.ecdf(seq(ceiling(max(mix.extinct, na.rm = T))))

# define cdf for theoretical probability density, where pars is the vector c(offset, K, tau)
my.tcdf <- function(pars) pext(seq(ceiling(max(mix.extinct, na.rm = T))), pars[1], pars[2], pars[3])

# define objective function to minimize, the sum squared error
my.objective <- function(pars) sum((my.tcdf(pars) - my.ecdf)^2)

# grid search across parameters
  # note: doing this manually, because built in optimizers do *not* like these density functions;
  # likely due to combination of bounded parameters and fractal discontinuities in parameter space,
  # see the SI in the paper.  On a laptop, fitting takes several hours to run.
  # TO DO: incorporate 'future' package to speed things up
off.search <- seq(200, 400, by = 10)
K.search <- seq(0.001, 0.249, length.out = 50)
tau.search <- seq(10, 500, length.out = 50)

ls.df <- expand.grid(off.search, K.search, tau.search)
names(ls.df) <- c("offset","K","tau")
ls.df$sse <- NA
ls.df$ic <- "mixed"

for( i in 1:nrow(ls.df) ) {
  ls.df$sse[i] <- my.objective(c(ls.df$offset[i], ls.df$K[i], ls.df$tau[i]))
  if( i %% 500 == 0 ) print(cat("Finished step", i, "of", nrow(ls.df), "\n"))
}

# save results
# write_csv(ls.df, "mixed_ic_ls_dist_fits.csv")

# examine fits
min.sse <- ls.df[which.min(ls.df$sse),]
min.sse

filter(ls.df, offset == min.sse$offset) %>%
  ggplot(aes(x = tau, y = K, fill = log(sse))) +
  geom_tile() +
  scale_fill_viridis_c()
  
plot(my.ecdf)
lines(my.tcdf(c(min.sse$offset, min.sse$K, min.sse$tau)), col = "red")

plot(density(mix.extinct, na.rm = T))
lines(density(sample(seq(10000), 741, prob = dext(seq(10000), min.sse$offset, min.sse$K, min.sse$tau))), col = "red")



### chaos ic ###

# probability density functions
chaos.ecdf <- ecdf(chaos.extinct)
my.chaos.ecdf <- chaos.ecdf(seq(ceiling(max(chaos.extinct, na.rm = T))))
my.chaos.tcdf <- function(pars) pext(seq(ceiling(max(chaos.extinct, na.rm = T))), pars[1], pars[2], pars[3])
my.chaos.objective <- function(pars) sum((my.chaos.tcdf(pars) - my.chaos.ecdf)^2)

# grid search 
off.search <- seq(200, 400, by = 10)
K.search <- seq(0.001, 0.249, length.out = 50)
tau.search <- seq(10, 500, length.out = 50)

ls.chaos.df <- expand.grid(off.search, K.search, tau.search)
names(ls.chaos.df) <- c("offset", "K","tau")
ls.chaos.df$sse <- NA
ls.chaos.df$ic <- "chaos"

for( i in 1:nrow(ls.chaos.df) ) {
  ls.chaos.df$sse[i] <- my.chaos.objective(c(ls.chaos.df$offset[i], ls.chaos.df$K[i], ls.chaos.df$tau[i]))
  if( i %% 500 == 0 ) print(paste("Finished step", i, "of", nrow(ls.chaos.df)))
}

# save output
# write_csv(ls.chaos.df, "chaos_ic_ls_dist_fits.csv")

# examine fits
min.chaos.sse <- ls.chaos.df[which.min(ls.chaos.df$sse),]
min.chaos.sse

filter(ls.chaos.df, offset == min.chaos.sse$offset) %>%
  ggplot(aes(x = tau, y = K, fill = sse)) +
  geom_tile() +
  scale_fill_viridis_c()

plot(my.chaos.ecdf)
lines(my.chaos.tcdf(c(min.chaos.sse$offset, min.chaos.sse$K, min.chaos.sse$tau)), col = "red")

plot(density(chaos.extinct))
lines(density(sample(seq(3000), 1000, replace = T, 
                     prob = dext(seq(3000), min.chaos.sse$offset, min.chaos.sse$K, min.chaos.sse$tau))), col = "red")


# Note:
# cyclic initial conditions can't really be fit (only observed extinction for ~3% of data)


### final figure ###

# read in data
chaos.fit <- read_csv("chaos_ic_ls_dist_fits.csv", col_types = "idddc")
mix.fit <- read_csv("mixed_ic_ls_dist_fits.csv", col_types = "idddc")

# best fits
min.chaos.sse <- chaos.fit[which.min(chaos.fit$sse),]
min.sse <- mix.fit[which.min(mix.fit$sse),]

# since ggplot is weird about multiple y axes, use bootstrap histograms in lieu 
  # of probability density overlay to get matched scales on y-axis
set.seed(42)
breaks <- seq(0, 10000, by = 100)

chaos.samples <- replicate(500,
                           sample(seq(max(chaos.extinct)), sum(is.finite(chaos.extinct)), replace = T,
                                  prob = dext(seq(max(chaos.extinct)), 
                                              min.chaos.sse$offset, min.chaos.sse$K, min.chaos.sse$tau)))
chaos.samples.hist <- apply(chaos.samples, 2, 
                            function(x) hist(x, plot = F, breaks = breaks)$counts)
chaos.samples.mean <- data.frame(mean = rowMeans(chaos.samples.hist),
                                 breaks = breaks[1:100] + 50, 
                                 ic = "chaos")

mix.samples <- replicate(500,
                         sample(seq(max(mix.extinct, na.rm = T)), sum(is.finite(mix.extinct)), replace = T,
                                prob = dext(seq(max(mix.extinct, na.rm = T)), 
                                            min.sse$offset, min.sse$K, min.sse$tau)))
mix.samples.hist <- apply(mix.samples, 2, 
                          function(x) hist(x, plot = F, breaks = breaks)$counts)
mix.samples.mean <- data.frame(mean = rowMeans(mix.samples.hist),
                               breaks = breaks[1:100] + 50,
                               ic = "mixed")

bootstrap.hist <- rbind(chaos.samples.mean, mix.samples.mean)

t.extinct %>%
  # prepare labels for plotting
  mutate(ic = fct_recode(ic, cycle = "lc"),
         ic = fct_relevel(ic, "cycle", "mixed", "chaos")) %>%
  # histograms
  ggplot(aes(t.extinct, fill = ic)) +
    geom_histogram(binwidth = 100) +
    # density overlay
    geom_line(data = bootstrap.hist, aes(x = breaks, y = mean), size = 2, alpha = 0.5, color = "black") +
    # prettify panels
    facet_grid(ic ~ .) +
    scale_fill_manual(values = c("#001889", "#7E028C", "#ECB519")) +
    labs(x = "time to extinction (doubling times)", y = "count") + 
    guides(fill = F) +
    panel_border()
